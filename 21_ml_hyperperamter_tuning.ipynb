{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import machine learning libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#import grid search for cv cross validation  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#import preprocessing libraries\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['total_bill', 'tip', 'sex', 'smoker', 'day', 'time', 'size'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load tips data\n",
    "df = sns.load_dataset('tips')\n",
    "df.head()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into X and y\n",
    "X = df.drop('tip', axis=1)\n",
    "y = df['tip']\n",
    "\n",
    "#label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create an instance of LabelEncoder using for loop\n",
    "for col in X.columns:\n",
    "    if X[col].dtypes == 'object' or X[col].dtypes == 'category':\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "\n",
    "#split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error for Linear Regression is  0.67\n",
      "Mean Absolute Error for SVR is  0.57\n",
      "Mean Absolute Error for Linear Regression is  0.67\n",
      "Mean Absolute Error for SVR is  0.57\n",
      "Mean Absolute Error for Linear Regression is  0.67\n",
      "Mean Absolute Error for Random Forest is  0.79\n",
      "Mean Absolute Error for SVR is  0.57\n",
      "Mean Absolute Error for Linear Regression is  0.67\n",
      "Mean Absolute Error for Gradient Boosting is  0.72\n",
      "Mean Absolute Error for Random Forest is  0.79\n",
      "Mean Absolute Error for SVR is  0.57\n",
      "Mean Absolute Error for Linear Regression is  0.67\n",
      "Mean Absolute Error for Gradient Boosting is  0.72\n",
      "Mean Absolute Error for Random Forest is  0.79\n",
      "Mean Absolute Error for Decision Tree is  0.88\n",
      "Mean Absolute Error for SVR is  0.57\n",
      "Mean Absolute Error for Linear Regression is  0.67\n",
      "Mean Absolute Error for Gradient Boosting is  0.72\n",
      "Mean Absolute Error for KNN is  0.73\n",
      "Mean Absolute Error for Random Forest is  0.79\n",
      "Mean Absolute Error for Decision Tree is  0.88\n",
      "Mean Absolute Error for SVR is  0.57\n",
      "Mean Absolute Error for Linear Regression is  0.67\n",
      "Mean Absolute Error for XGBoost is  0.67\n",
      "Mean Absolute Error for Gradient Boosting is  0.72\n",
      "Mean Absolute Error for KNN is  0.73\n",
      "Mean Absolute Error for Random Forest is  0.79\n",
      "Mean Absolute Error for Decision Tree is  0.88\n"
     ]
    }
   ],
   "source": [
    "#create a disctionary of models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'SVR': SVR(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'KNN': KNeighborsRegressor(),\n",
    "    'XGBoost': XGBRegressor()\n",
    "}\n",
    "\n",
    "#train and predict the models\n",
    "models_scores = []\n",
    "for model_name, model in models.items():\n",
    "    #train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    #predict the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    metric=mean_absolute_error(y_test, y_pred)\n",
    "    models_scores.append((model_name, metric))\n",
    "\n",
    "    #sorted the models\n",
    "    sorted_models = sorted(models_scores, key=lambda x: x[1], reverse=False)\n",
    "    for model in sorted_models:\n",
    "    #  print the models output one time only\n",
    "       print('Mean Absolute Error for', f\"{model[0]} is {model[1]: .2f}\")\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for Linear Regression is  0.69\n",
      "Mean Squared Error for SVR is  0.54\n",
      "Mean Squared Error for Linear Regression is  0.69\n",
      "Mean Squared Error for SVR is  0.54\n",
      "Mean Squared Error for Linear Regression is  0.69\n",
      "Mean Squared Error for Random Forest is  0.94\n",
      "Mean Squared Error for SVR is  0.54\n",
      "Mean Squared Error for Linear Regression is  0.69\n",
      "Mean Squared Error for Gradient Boosting is  0.81\n",
      "Mean Squared Error for Random Forest is  0.94\n",
      "Mean Squared Error for SVR is  0.54\n",
      "Mean Squared Error for Linear Regression is  0.69\n",
      "Mean Squared Error for Gradient Boosting is  0.81\n",
      "Mean Squared Error for Random Forest is  0.94\n",
      "Mean Squared Error for Decision Tree is  1.39\n",
      "Mean Squared Error for SVR is  0.54\n",
      "Mean Squared Error for Linear Regression is  0.69\n",
      "Mean Squared Error for Gradient Boosting is  0.81\n",
      "Mean Squared Error for KNN is  0.84\n",
      "Mean Squared Error for Random Forest is  0.94\n",
      "Mean Squared Error for Decision Tree is  1.39\n",
      "Mean Squared Error for SVR is  0.54\n",
      "Mean Squared Error for Linear Regression is  0.69\n",
      "Mean Squared Error for XGBoost is  0.74\n",
      "Mean Squared Error for Gradient Boosting is  0.81\n",
      "Mean Squared Error for KNN is  0.84\n",
      "Mean Squared Error for Random Forest is  0.94\n",
      "Mean Squared Error for Decision Tree is  1.39\n"
     ]
    }
   ],
   "source": [
    "#create a disctionary of models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'SVR': SVR(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'KNN': KNeighborsRegressor(),\n",
    "    'XGBoost': XGBRegressor()\n",
    "}\n",
    "\n",
    "#train and predict the models\n",
    "models_scores = []\n",
    "for model_name, model in models.items():\n",
    "    #train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    #predict the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    metric=mean_squared_error(y_test, y_pred)\n",
    "    models_scores.append((model_name, metric))\n",
    "\n",
    "    #sorted the models\n",
    "    sorted_models = sorted(models_scores, key=lambda x: x[1], reverse=False)\n",
    "    for model in sorted_models:\n",
    "       print('Mean Squared Error for', f\"{model[0]} is {model[1]: .2f}\")\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean square Error for Linear Regression is  0.83\n",
      "Root mean square Error for SVR is  0.73\n",
      "Root mean square Error for Linear Regression is  0.83\n",
      "Root mean square Error for SVR is  0.73\n",
      "Root mean square Error for Linear Regression is  0.83\n",
      "Root mean square Error for Random Forest is  0.98\n",
      "Root mean square Error for SVR is  0.73\n",
      "Root mean square Error for Linear Regression is  0.83\n",
      "Root mean square Error for Gradient Boosting is  0.90\n",
      "Root mean square Error for Random Forest is  0.98\n",
      "Root mean square Error for SVR is  0.73\n",
      "Root mean square Error for Linear Regression is  0.83\n",
      "Root mean square Error for Gradient Boosting is  0.90\n",
      "Root mean square Error for Random Forest is  0.98\n",
      "Root mean square Error for Decision Tree is  1.17\n",
      "Root mean square Error for SVR is  0.73\n",
      "Root mean square Error for Linear Regression is  0.83\n",
      "Root mean square Error for Gradient Boosting is  0.90\n",
      "Root mean square Error for KNN is  0.92\n",
      "Root mean square Error for Random Forest is  0.98\n",
      "Root mean square Error for Decision Tree is  1.17\n",
      "Root mean square Error for SVR is  0.73\n",
      "Root mean square Error for Linear Regression is  0.83\n",
      "Root mean square Error for XGBoost is  0.86\n",
      "Root mean square Error for Gradient Boosting is  0.90\n",
      "Root mean square Error for KNN is  0.92\n",
      "Root mean square Error for Random Forest is  0.98\n",
      "Root mean square Error for Decision Tree is  1.17\n"
     ]
    }
   ],
   "source": [
    "#create a disctionary of models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'SVR': SVR(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'KNN': KNeighborsRegressor(),\n",
    "    'XGBoost': XGBRegressor()\n",
    "}\n",
    "\n",
    "#train and predict the models\n",
    "models_scores = []\n",
    "for model_name, model in models.items():\n",
    "    #train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    #predict the model\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "     #root mean squared error\n",
    "    metric=np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    models_scores.append((model_name, metric))\n",
    "\n",
    "    #sorted the models\n",
    "    sorted_models = sorted(models_scores, key=lambda x: x[1], reverse=False)\n",
    "    for model in sorted_models:\n",
    "       print('Root mean square Error for', f\"{model[0]} is {model[1]: .2f}\")\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f models to perform hyperparameter tuning\n",
    "# Define the hyperparameters grid for each model\n",
    "param_grid = {\n",
    "    'Linear Regression': {'normalize': [True, False]},\n",
    "    'SVR': {'kernel': ['linear', 'poly', 'rbf']},\n",
    "    'Random Forest': {'n_estimators': [100, 200, 300], 'max_depth': [None, 5, 10]},\n",
    "    'Gradient Boosting': {'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 200, 300]},\n",
    "    'Decision Tree': {'max_depth': [None, 5, 10], 'min_samples_split': [2, 5, 10]},\n",
    "    'KNN': {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']},\n",
    "    'XGBoost': {'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 200, 300]}\n",
    "}\n",
    "\n",
    "# Perform hyperparameter tuning for each model\n",
    "for model_name, model in models.items():\n",
    "    grid_search = GridSearchCV(model, param_grid[model_name], cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best parameters for {model_name}: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add the preprocesser inside the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
